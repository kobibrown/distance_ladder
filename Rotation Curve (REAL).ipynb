{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2f4393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.signal import savgol_filter\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the inclination_correction and radial_distance functions\n",
    "def inclination_correction(major, minor, emax, method):\n",
    "    if minor > major:\n",
    "        major, minor = minor, major\n",
    "        \n",
    "    eccentricity = np.sqrt(1 - (minor / major) ** 2)\n",
    "    if method == \"sine\":\n",
    "        vel_multiplier = np.sin(np.pi / 2 * (eccentricity / emax))\n",
    "    else:\n",
    "        vel_multiplier = np.cos(np.pi / 2 * (1 - eccentricity / emax))\n",
    "    return vel_multiplier\n",
    "\n",
    "\n",
    "def radial_distance(galax_x, galax_y, star_x, star_y):\n",
    "    delta_x = star_x - galax_x\n",
    "    delta_y = galax_y - star_y\n",
    "    distance = np.sqrt((delta_x) ** 2 + (delta_y) ** 2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Load data from the CSV files\n",
    "data = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/clustered_star_data.csv')\n",
    "results_df = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/Cluster_Ellipse_Data.csv')\n",
    "\n",
    "\n",
    "def plot_rotation_curve(cluster_number, output_folder):\n",
    "    # Filter the galaxy_data DataFrame for the desired cluster\n",
    "    filtered_data = data.loc[data['cluster'] == cluster_number].copy()\n",
    "\n",
    "    # account for the proper motion of the galaxy\n",
    "    filtered_data.loc[:, 'RadialVelocity'] -= filtered_data['RadialVelocity'].median()\n",
    "\n",
    "    # pull ellipse data\n",
    "    ellipse_data = results_df.loc[results_df['cluster'] == cluster_number]\n",
    "    major_axis = ellipse_data['major_axis'].values[0]\n",
    "    minor_axis = ellipse_data['minor_axis'].values[0]\n",
    "\n",
    "    # correct the star velocities\n",
    "    emax = np.sqrt(1 - (0.1143347 / 0.4066884) ** 2)  # Maximum eccentricity chosen as edge-on cluster 5\n",
    "    velocity_correction = 1 / inclination_correction(major_axis, minor_axis, emax, \"cos\")\n",
    "    corrected_velocities = abs(filtered_data['RadialVelocity'] * velocity_correction)\n",
    "\n",
    "    # find the position of each star relative to the centre\n",
    "    center_x = ellipse_data['center_x'].values[0]\n",
    "    center_y = ellipse_data['center_y'].values[0]\n",
    "    radii = [radial_distance(center_x, center_y, x, y) for x, y in zip(filtered_data['Equat'], filtered_data['Polar'])]\n",
    "\n",
    "    # normalize the radial distances\n",
    "    normalized_radii = np.array(radii) / max(radii)\n",
    "\n",
    "    # average the corrected radial velocities over the x values\n",
    "    n_bins = 5\n",
    "    bin_means, bin_edges = np.histogram(normalized_radii, bins=n_bins, weights=corrected_velocities)\n",
    "    bin_count, _ = np.histogram(normalized_radii, bins=n_bins)\n",
    "    bin_count = bin_count.astype(float)\n",
    "    bin_count[bin_count == 0] = np.nan\n",
    "    bin_means = np.divide(bin_means, bin_count)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    #  line of best fit\n",
    "    best_fit_spline = UnivariateSpline(bin_centers, bin_means, s=0)\n",
    "    x_vals = np.concatenate(([0], np.linspace(0, max(normalized_radii), 100)))\n",
    "\n",
    "    n_bins = 25\n",
    "    ceiling_radii, ceiling_velocities = ceiling_fit_radii_velocities(normalized_radii, corrected_velocities, n_bins)\n",
    "\n",
    "    # smoothing algo\n",
    "    window_size, polyorder = 20, 5\n",
    "    smoothed_ceiling_radii, smoothed_ceiling_velocities = smooth_curve(ceiling_radii, ceiling_velocities, window_size, polyorder)\n",
    "\n",
    "    # force the origin start\n",
    "    smoothed_ceiling_radii = np.insert(smoothed_ceiling_radii, 0, 0)\n",
    "    smoothed_ceiling_velocities = np.insert(smoothed_ceiling_velocities, 0, 0)\n",
    "\n",
    "    # Create the rotation curve plot\n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.scatter(normalized_radii, corrected_velocities, c=filtered_data['RadialVelocity'], cmap='RdBu', s=10, label='Stars')\n",
    "    plt.plot(smoothed_ceiling_radii, smoothed_ceiling_velocities, 'k-', linewidth=2, label='Rotation Curve')\n",
    "    plt.xlabel('Normalized Radial Distance')\n",
    "    plt.ylabel('Corrected Radial Velocity (km/s)')\n",
    "    plt.colorbar(label='Observed Radial Velocity (km/s)')\n",
    "    plt.title(f'Rotation Curve for Cluster {cluster_number}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.savefig(os.path.join(output_folder, f'rotation_curve_cluster_{cluster_number}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def smooth_curve(x, y, window_size, polyorder):\n",
    "    if len(y) < window_size:\n",
    "        window_size = len(y) - 1 if len(y) % 2 == 0 else len(y)\n",
    "    smoothed_y = savgol_filter(y, window_size, polyorder)\n",
    "    return x, smoothed_y\n",
    "\n",
    "# Set the output folder\n",
    "output_folder = \"/Users/kobibrown/Desktop/Distance_Ladder_Project/Rotation_Curves\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get all unique cluster numbers\n",
    "unique_clusters = data['cluster'].unique()\n",
    "\n",
    "# Loop over all clusters and export pngs of all the rotation curves to the specified folder\n",
    "for cluster_number in unique_clusters:\n",
    "    plot_rotation_curve(cluster_number, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b03362d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Define the inclination_correction and radial_distance functions\n",
    "def inclination_correction(major, minor, emax, method):\n",
    "    if minor > major:\n",
    "        major, minor = minor, major\n",
    "        \n",
    "    eccentricity = np.sqrt(1 - (minor / major) ** 2)\n",
    "    if method == \"sine\":\n",
    "        vel_multiplier = np.sin(np.pi / 2 * (eccentricity / emax))\n",
    "    else:\n",
    "        vel_multiplier = np.cos(np.pi / 2 * (1 - eccentricity / emax))\n",
    "    return vel_multiplier\n",
    "\n",
    "\n",
    "def radial_distance(galax_x, galax_y, star_x, star_y):\n",
    "    delta_x = star_x - galax_x\n",
    "    delta_y = galax_y - star_y\n",
    "    distance = np.sqrt((delta_x) ** 2 + (delta_y) ** 2)\n",
    "    return distance\n",
    "\n",
    "def ceiling_fit_radii_velocities(x, y, n_bins, zscore_threshold=2, iqr_multiplier=1.5):\n",
    "    # Remove outliers using the IQR method for both x and y\n",
    "    cleaned_x, cleaned_y = remove_velocity_outliers_iqr(x, y, iqr_multiplier)\n",
    "    cleaned_x, cleaned_y = remove_velocity_outliers_iqr(cleaned_x, cleaned_y, iqr_multiplier)\n",
    "\n",
    "    # Bin the data using the max statistic\n",
    "    bin_means, bin_edges, binnumber = stats.binned_statistic(cleaned_x, cleaned_y, statistic='max', bins=n_bins)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Remove bins with NaN (occurs when there's no data in the bin)\n",
    "    non_nan_indices = np.where(~np.isnan(bin_means))\n",
    "    cleaned_bin_centers = bin_centers[non_nan_indices]\n",
    "    cleaned_bin_means = bin_means[non_nan_indices]\n",
    "\n",
    "    return cleaned_bin_centers, cleaned_bin_means\n",
    "\n",
    "\n",
    "\n",
    "# Load data from the CSV files\n",
    "data = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/clustered_star_data.csv')\n",
    "results_df = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/Cluster_Ellipse_Data.csv')\n",
    "\n",
    "\n",
    "def plot_rotation_curve(cluster_number, output_folder):\n",
    "    # Filter the galaxy_data DataFrame for the desired cluster\n",
    "    filtered_data = data.loc[data['cluster'] == cluster_number].copy()\n",
    "\n",
    "    # account for the proper motion of the galaxy\n",
    "    filtered_data.loc[:, 'RadialVelocity'] -= filtered_data['RadialVelocity'].median()\n",
    "\n",
    "    # pull ellipse data\n",
    "    ellipse_data = results_df.loc[results_df['cluster'] == cluster_number]\n",
    "    major_axis = ellipse_data['major_axis'].values[0]\n",
    "    minor_axis = ellipse_data['minor_axis'].values[0]\n",
    "\n",
    "    # correct the star velocities\n",
    "    emax = np.sqrt(1 - (0.1143347 / 0.4066884) ** 2)  # Maximum eccentricity chosen as edge-on cluster 5\n",
    "    velocity_correction = 1 / inclination_correction(major_axis, minor_axis, emax, \"cos\")\n",
    "    corrected_velocities = abs(filtered_data['RadialVelocity'] * velocity_correction)\n",
    "\n",
    "    # Convert corrected_velocities to a numpy array\n",
    "    corrected_velocities = corrected_velocities.to_numpy()\n",
    "\n",
    "    # Convert corrected_velocities back to a pandas Series\n",
    "    corrected_velocities = pd.Series(corrected_velocities)\n",
    "\n",
    "\n",
    "\n",
    "    # find the position of each star relative to the centre\n",
    "    center_x = ellipse_data['center_x'].values[0]\n",
    "    center_y = ellipse_data['center_y'].values[0]\n",
    "    radii = [radial_distance(center_x, center_y, x, y) for x, y in zip(filtered_data['Equat'], filtered_data['Polar'])]\n",
    "\n",
    "    # normalize the radial distances\n",
    "    normalized_radii = np.array(radii) / max(radii)\n",
    "\n",
    "    # average the corrected radial velocities over the x values\n",
    "    n_bins = 5\n",
    "    ceiling_radii, ceiling_velocities = ceiling_fit_radii_velocities(normalized_radii, corrected_velocities, n_bins)\n",
    "\n",
    "    if len(ceiling_radii) < 2 or len(ceiling_velocities) < 2:\n",
    "        print(f\"Skipping cluster {cluster_number} due to insufficient data for interpolation.\")\n",
    "        return\n",
    "\n",
    "    # Add the origin to the ceiling_radii and ceiling_velocities arrays\n",
    "    ceiling_radii = np.concatenate(([0], ceiling_radii))\n",
    "    ceiling_velocities = np.concatenate(([0], ceiling_velocities))\n",
    "\n",
    "    # Create the PCHIP interpolator\n",
    "    pchip_interpolator = PchipInterpolator(ceiling_radii, ceiling_velocities)\n",
    "    x_vals = np.linspace(0, max(normalized_radii), 100)\n",
    "    pchip_y = pchip_interpolator(x_vals)\n",
    "\n",
    "    # Clip the pchip_y values to ensure the curve doesn't go beyond the plot's limits\n",
    "    max_ceiling_velocity = np.max(ceiling_velocities)\n",
    "    pchip_y = np.clip(pchip_y, 0, max_ceiling_velocity)\n",
    "\n",
    "\n",
    "    # Create the rotation curve plot\n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.scatter(normalized_radii, corrected_velocities, c=filtered_data['RadialVelocity'], cmap='RdBu', s=10, label='Stars')\n",
    "    plt.plot(x_vals, pchip_y, 'k-', linewidth=2, label='Rotation Curve')\n",
    "\n",
    "    plt.xlabel('Normalized Distance from the Centre of The Galaxy', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Corrected Radial Velocity (km/s)', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Rotation Curve for Cluster {cluster_number}', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    cbar = plt.colorbar(label='Observed Radial Velocity (km/s)')\n",
    "    cbar.ax.set_ylabel('Observed Radial Velocity (km/s)', fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "    # Set the y-axis limits to focus on the majority of the data\n",
    "    q1 = np.percentile(cleaned_corrected_velocities, 25)\n",
    "    q3 = np.percentile(cleaned_corrected_velocities, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1 * iqr\n",
    "\n",
    "    # Set the upper bound to be just above the highest point of the fitted line\n",
    "    highest_fitted_point = np.max(pchip_y)\n",
    "    padding_factor = 1.1  # Adjust this value to change the headroom above the highest point\n",
    "    upper_bound = highest_fitted_point * padding_factor\n",
    "\n",
    "    plt.ylim(lower_bound, upper_bound)\n",
    "\n",
    "    plt.savefig(os.path.join(output_folder, f'rotation_curve_cluster_{cluster_number}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "smoothed_ceiling_radii, smoothed_ceiling_velocities = smooth_curve(ceiling_radii, ceiling_velocities, window_size_fraction=0.2, polyorder=5)\n",
    "\n",
    "def remove_velocity_outliers_iqr(x, y, iqr_multiplier=1.5):\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - iqr_multiplier * iqr\n",
    "    upper_bound = q3 + iqr_multiplier * iqr\n",
    "    good_indices = np.where((y > lower_bound) & (y < upper_bound))\n",
    "    cleaned_x = x[good_indices]\n",
    "    cleaned_y = y.iloc[good_indices]  # Use .iloc indexer\n",
    "    return cleaned_x, cleaned_y\n",
    "\n",
    "\n",
    "cleaned_normalized_radii, cleaned_corrected_velocities = remove_velocity_outliers_iqr(normalized_radii, corrected_velocities, iqr_multiplier=1.5)\n",
    "\n",
    "\n",
    "\n",
    "# Set the output folder\n",
    "output_folder = \"/Users/kobibrown/Desktop/Distance_Ladder_Project/Rotation_Curves\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get all unique cluster numbers\n",
    "unique_clusters = data['cluster'].unique()\n",
    "\n",
    "# Loop over all clusters and export pngs of all the rotation curves to the specified folder\n",
    "for cluster_number in unique_clusters:\n",
    "    plot_rotation_curve(cluster_number, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2cc17cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy import stats\n",
    "import os\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "\n",
    "# Define the inclination_correction and radial_distance functions\n",
    "def inclination_correction(major, minor, emax, method):\n",
    "    if minor > major:\n",
    "        major, minor = minor, major\n",
    "        \n",
    "    eccentricity = np.sqrt(1 - (minor / major) ** 2)\n",
    "    if method == \"sine\":\n",
    "        vel_multiplier = np.sin(np.pi / 2 * (eccentricity / emax))\n",
    "    else:\n",
    "        vel_multiplier = np.cos(np.pi / 2 * (1 - eccentricity / emax))\n",
    "    return vel_multiplier\n",
    "\n",
    "\n",
    "def radial_distance(galax_x, galax_y, star_x, star_y):\n",
    "    delta_x = star_x - galax_x\n",
    "    delta_y = galax_y - star_y\n",
    "    distance = np.sqrt((delta_x) ** 2 + (delta_y) ** 2)\n",
    "    return distance\n",
    "\n",
    "def ceiling_fit_radii_velocities(x, y, n_bins, zscore_threshold=2, iqr_multiplier=1.5):\n",
    "    # Remove outliers using the IQR method for both x and y\n",
    "    cleaned_x, cleaned_y = remove_velocity_outliers_iqr(x, y, iqr_multiplier)\n",
    "    cleaned_x, cleaned_y = remove_velocity_outliers_iqr(cleaned_x, cleaned_y, iqr_multiplier)\n",
    "\n",
    "    # Bin the data using the max statistic\n",
    "    bin_means, bin_edges, binnumber = stats.binned_statistic(cleaned_x, cleaned_y, statistic='max', bins=n_bins)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Remove bins with NaN (occurs when there's no data in the bin)\n",
    "    non_nan_indices = np.where(~np.isnan(bin_means))\n",
    "    cleaned_bin_centers = bin_centers[non_nan_indices]\n",
    "    cleaned_bin_means = bin_means[non_nan_indices]\n",
    "\n",
    "    return cleaned_bin_centers, cleaned_bin_means\n",
    "\n",
    "\n",
    "\n",
    "# Load data from the CSV files\n",
    "data = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/clustered_star_data.csv')\n",
    "results_df = pd.read_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/Cluster_Ellipse_Data.csv')\n",
    "\n",
    "def fit_log_line_to_ceiling(x, y):\n",
    "    x = x[1:]  # Exclude the first element (0) to avoid log(0) warning\n",
    "    y = y[1:]  # Exclude the first element (0) to avoid log(0) warning\n",
    "    \n",
    "    # Add an intermediate point between the origin and the first ceiling point\n",
    "    x = np.concatenate(([0.5 * x[0]], x))\n",
    "    y = np.concatenate(([0.5 * y[0]], y))\n",
    "    \n",
    "    log_x = np.log10(x)\n",
    "    log_y = np.log10(y)\n",
    "    cubic_spline_interpolator = CubicSpline(log_x, log_y, bc_type=\"natural\")\n",
    "    num_points = 100  # Number of points for the log fit\n",
    "    log_fit_x_vals = np.linspace(min(log_x), max(log_x), num_points)\n",
    "    log_fit_y = cubic_spline_interpolator(log_fit_x_vals)\n",
    "    fit_x = np.concatenate(([0], 10**log_fit_x_vals))\n",
    "    fit_y = np.concatenate(([0], 10**log_fit_y))\n",
    "    return fit_x, fit_y\n",
    "\n",
    "def plot_rotation_curve(cluster_number, output_folder):\n",
    "    # Filter the galaxy_data DataFrame for the desired cluster\n",
    "    filtered_data = data.loc[data['cluster'] == cluster_number].copy()\n",
    "\n",
    "    # account for the proper motion of the galaxy\n",
    "    filtered_data.loc[:, 'RadialVelocity'] -= filtered_data['RadialVelocity'].median()\n",
    "\n",
    "    # pull ellipse data\n",
    "    ellipse_data = results_df.loc[results_df['cluster'] == cluster_number]\n",
    "    major_axis = ellipse_data['major_axis'].values[0]\n",
    "    minor_axis = ellipse_data['minor_axis'].values[0]\n",
    "\n",
    "    # correct the star velocities\n",
    "    emax = np.sqrt(1 - (0.1143347 / 0.4066884) ** 2)  # Maximum eccentricity chosen as edge-on cluster 5\n",
    "    velocity_correction = 1 / inclination_correction(major_axis, minor_axis, emax, \"cos\")\n",
    "    corrected_velocities = abs(filtered_data['RadialVelocity'] * velocity_correction)\n",
    "\n",
    "    # Convert corrected_velocities to a numpy array\n",
    "    corrected_velocities = corrected_velocities.to_numpy()\n",
    "\n",
    "    # Convert corrected_velocities back to a pandas Series\n",
    "    corrected_velocities = pd.Series(corrected_velocities)\n",
    "\n",
    "\n",
    "\n",
    "    # find the position of each star relative to the centre\n",
    "    center_x = ellipse_data['center_x'].values[0]\n",
    "    center_y = ellipse_data['center_y'].values[0]\n",
    "    radii = [radial_distance(center_x, center_y, x, y) for x, y in zip(filtered_data['Equat'], filtered_data['Polar'])]\n",
    "\n",
    "    # normalize the radial distances\n",
    "    normalized_radii = np.array(radii) / max(radii)\n",
    "\n",
    "    # average the corrected radial velocities over the x values\n",
    "    n_bins = 5\n",
    "    ceiling_radii, ceiling_velocities = ceiling_fit_radii_velocities(normalized_radii, corrected_velocities, n_bins)\n",
    "\n",
    "    if len(ceiling_radii) < 2 or len(ceiling_velocities) < 2:\n",
    "        print(f\"Skipping cluster {cluster_number} due to insufficient data for interpolation.\")\n",
    "        return\n",
    "\n",
    "    # Add the origin to the ceiling_radii and ceiling_velocities arrays\n",
    "    ceiling_radii = np.concatenate(([0], ceiling_radii))\n",
    "    ceiling_velocities = np.concatenate(([0], ceiling_velocities))\n",
    "\n",
    "    # Create the PCHIP interpolator\n",
    "    pchip_interpolator = PchipInterpolator(ceiling_radii, ceiling_velocities)\n",
    "    x_vals = np.linspace(0, max(normalized_radii), 100)\n",
    "    pchip_y = pchip_interpolator(x_vals)\n",
    "\n",
    "    # Clip the pchip_y values to ensure the curve doesn't go beyond the plot's limits\n",
    "    max_ceiling_velocity = np.max(ceiling_velocities)\n",
    "    pchip_y = np.clip(pchip_y, 0, max_ceiling_velocity)\n",
    "\n",
    "\n",
    "    # Fit a smooth log line to the ceiling of the data\n",
    "    log_fit_x, log_fit_y = fit_log_line_to_ceiling(ceiling_radii, ceiling_velocities)\n",
    "\n",
    "    # Create the rotation curve plot\n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.scatter(normalized_radii, corrected_velocities, c=filtered_data['RadialVelocity'], cmap='RdBu', s=10, label='Stars')\n",
    "    plt.plot(log_fit_x, log_fit_y, 'k-', linewidth=1, label='Rotation Curve')\n",
    "\n",
    "\n",
    "    plt.xlabel('Normalized Distance from the Centre of The Galaxy', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Corrected Rotational Velocity (km/s)', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Rotation Curve for Cluster {cluster_number}', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    cbar = plt.colorbar(label='Corrected Radial Velocity (km/s)')\n",
    "    cbar.ax.set_ylabel('Corrected Radial Velocity (km/s)', fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "    # Set the y-axis limits to focus on the majority of the data\n",
    "    q1 = np.percentile(cleaned_corrected_velocities, 25)\n",
    "    q3 = np.percentile(cleaned_corrected_velocities, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1 * iqr\n",
    "\n",
    "    # Set the upper bound to be just above the highest point of the fitted line\n",
    "    highest_fitted_point = np.max(pchip_y)\n",
    "    padding_factor = 1.1  # Adjust this value to change the headroom above the highest point\n",
    "    upper_bound = highest_fitted_point * padding_factor\n",
    "\n",
    "    plt.ylim(lower_bound, upper_bound)\n",
    "\n",
    "    plt.savefig(os.path.join(output_folder, f'rotation_curve_cluster_{cluster_number}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "smoothed_ceiling_radii, smoothed_ceiling_velocities = smooth_curve(ceiling_radii, ceiling_velocities, window_size_fraction=0.2, polyorder=5)\n",
    "\n",
    "def remove_velocity_outliers_iqr(x, y, iqr_multiplier=1.5):\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - iqr_multiplier * iqr\n",
    "    upper_bound = q3 + iqr_multiplier * iqr\n",
    "    good_indices = np.where((y > lower_bound) & (y < upper_bound))\n",
    "    cleaned_x = x[good_indices]\n",
    "    cleaned_y = y.iloc[good_indices]  # Use .iloc indexer\n",
    "    return cleaned_x, cleaned_y\n",
    "\n",
    "\n",
    "cleaned_normalized_radii, cleaned_corrected_velocities = remove_velocity_outliers_iqr(normalized_radii, corrected_velocities, iqr_multiplier=1.5)\n",
    "\n",
    "\n",
    "\n",
    "# Set the output folder\n",
    "output_folder = \"/Users/kobibrown/Desktop/Distance_Ladder_Project/Rotation_Curves\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get all unique cluster numbers\n",
    "unique_clusters = data['cluster'].unique()\n",
    "\n",
    "# Loop over all clusters and export pngs of all the rotation curves to the specified folder\n",
    "for cluster_number in unique_clusters:\n",
    "    plot_rotation_curve(cluster_number, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "71b7837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the maximum velocities for each cluster\n",
    "max_velocities = []\n",
    "\n",
    "# Loop over all clusters and find the maximum corrected rotational velocity\n",
    "for cluster_number in unique_clusters:\n",
    "    # Filter the galaxy_data DataFrame for the desired cluster\n",
    "    filtered_data = data.loc[data['cluster'] == cluster_number].copy()\n",
    "\n",
    "    # account for the proper motion of the galaxy\n",
    "    filtered_data.loc[:, 'RadialVelocity'] -= filtered_data['RadialVelocity'].median()\n",
    "\n",
    "    # pull ellipse data\n",
    "    ellipse_data = results_df.loc[results_df['cluster'] == cluster_number]\n",
    "    major_axis = ellipse_data['major_axis'].values[0]\n",
    "    minor_axis = ellipse_data['minor_axis'].values[0]\n",
    "\n",
    "    # correct the star velocities\n",
    "    emax = np.sqrt(1 - (0.1143347 / 0.4066884) ** 2)  # Maximum eccentricity chosen as edge-on cluster 5\n",
    "    velocity_correction = 1 / inclination_correction(major_axis, minor_axis, emax, \"cos\")\n",
    "    corrected_velocities = abs(filtered_data['RadialVelocity'] * velocity_correction)\n",
    "\n",
    "    # Get the maximum velocity for this cluster\n",
    "    max_velocities.append(corrected_velocities.max())\n",
    "\n",
    "# Create a DataFrame with columns for cluster numbers and maximum velocities\n",
    "output_df = pd.DataFrame({'cluster': unique_clusters, 'max_corrected_rotational_velocity': max_velocities})\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "output_df.to_csv('/Users/kobibrown/Desktop/Distance_Ladder_Project/max_rotational_velocities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb167f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
